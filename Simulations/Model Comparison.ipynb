{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import logsumexp\n",
    "from collections import defaultdict\n",
    "from Scripts import OrderedCategorySystem as OCS\n",
    "from Scripts import generate_plots as plots\n",
    "from Scripts import order_analyses as analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde579c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "F =  [12, 13, 15, 14, 16, 18, 17, 19, 20]\n",
    "B =  [20, 19, 17, 18, 16, 14, 15, 13, 12]\n",
    "M1 =  [16, 17, 15, 18, 14, 19, 13, 20, 12]\n",
    "M2 = [16, 15, 17, 14, 18, 13, 19, 12, 20]\n",
    "\n",
    "NEW = [i for i in range(9, 24)]\n",
    "ALL = NEW + [1, 3, 29, 31]\n",
    "\n",
    "SHIFT = 3\n",
    "DISTRACTORS = [1, 3, 29, 31]\n",
    "\n",
    "ITEMS = ['I09', 'I10', 'I11', 'I12', 'I13', 'I14', 'I15', 'I16', 'I17', 'I18', 'I19', 'I20', 'I21', 'I22', 'I23']\n",
    "\n",
    "LEFT = ITEMS[:9]\n",
    "CENTRE = ITEMS[3:12]\n",
    "RIGHT = ITEMS[6:]\n",
    "\n",
    "LOCS = [('L', LEFT),\n",
    "        ('C', CENTRE), \n",
    "        ('R', RIGHT)]\n",
    "ORDERS = [('f', 0, [1, 2, 3, 4, 5, 6, 7, 8]),\n",
    "          ('m', 4, [0, 1, 2, 3, 5, 6, 7, 8]),\n",
    "          ('b', 8, [0, 1, 2, 3, 4, 5, 6, 7])]\n",
    "\n",
    "item_space = [i for i in range(1, 32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcffd3",
   "metadata": {},
   "source": [
    "### Load Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a53d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allParticipants = pd.read_csv('../Analysis/Results/participant_data.csv')\n",
    "allParticipants =  allParticipants[(allParticipants['ATTEMPTS'] < 3) & (allParticipants['TOTAL_ERRORS'] < 4)]\n",
    "participants = allParticipants['P_ID'].tolist()\n",
    "\n",
    "participant_df = pd.read_csv('../Analysis/Results/trial_data.csv')    \n",
    "participant_df = participant_df[participant_df['P_ID'].isin(participants)]\n",
    "\n",
    "cat_assigns = ITEMS + ['I01', 'I03', 'I29', 'I31']\n",
    "others = participant_df.columns.difference(cat_assigns)\n",
    "\n",
    "participant_df = (\n",
    "    participant_df[others]\n",
    "      .assign(ITEMS = participant_df[cat_assigns].agg(\n",
    "            lambda row: {k: v for k, v in row.items() if not pd.isna(v)},\n",
    "            axis=1\n",
    "        )\n",
    "      )\n",
    ")\n",
    "participant_trials = list(participant_df.to_dict('index').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_possible_sets(order, loc):\n",
    "    distract_orders =  list(itertools.permutations(DISTRACTORS))\n",
    "    if order in ['f', 'b', 'm']: # Sequence\n",
    "        if order == 'f':\n",
    "            item_orders = [F]\n",
    "        elif order == 'b':\n",
    "            item_orders = [B]\n",
    "        else:\n",
    "            item_orders = [M1, M2]\n",
    "    possible_orders = []\n",
    "    for i_ord in item_orders:\n",
    "        for d_ord in distract_orders:\n",
    "            if loc == 'L':\n",
    "                loc_ord = [i-SHIFT for i in i_ord]\n",
    "            elif loc == 'R':\n",
    "                loc_ord = [i+SHIFT for i in i_ord]\n",
    "            else:\n",
    "                loc_ord = i_ord\n",
    "            final_ord = loc_ord[0:1] + [d_ord[0]] + loc_ord[1:4] + [d_ord[1]] + loc_ord[4:5] + [d_ord[2]] + loc_ord[5:8] + [d_ord[3]]+ loc_ord[8:9]\n",
    "            possible_orders.append(final_ord)\n",
    "    return possible_orders\n",
    "            \n",
    "    \n",
    "def analyze_participant(cat_assigns, orders, syst, D, lookupTree=None, temp=1):\n",
    "    log_likes = []\n",
    "    if lookupTree is None:\n",
    "        lookupTree = defaultdict(lambda: None)\n",
    "    for i_ord in orders:\n",
    "        start_syst = copy.deepcopy(syst)\n",
    "        log_like = OCS.model_likelihood(start_syst, cat_assigns, i_ord, D, lookupTree, temp)\n",
    "        log_likes.append(log_like)\n",
    "    marginal_like = logsumexp(log_likes) - np.log(len(orders))\n",
    "    max_like = max(log_likes)\n",
    "    min_like = min(log_likes)\n",
    "    return marginal_like, max_like, min_like\n",
    "\n",
    "def generate_all_orderings():\n",
    "    order_dic = {}\n",
    "    for loc in ['L', 'C', 'R']:\n",
    "        for order in ['f', 'b', 'm']:\n",
    "            order_dic[f'{loc}{order}'] = generate_possible_sets(order, loc)\n",
    "\n",
    "    return order_dic\n",
    "\n",
    "def estimate_model_likelihood(trials, temp=1):\n",
    "    log_like = 0\n",
    "    worst_like = 0\n",
    "    best_like = 0\n",
    "    p = 0\n",
    "    order_dic = generate_all_orderings()\n",
    "    D, item_hash = OCS.get_distance_mat(item_space)\n",
    "    lookupTree = defaultdict(lambda: None) # can only do this here if assuming items are the same across trees. \n",
    "    for t in trials:\n",
    "        d, l, o = t['DEPTH'], t['LOC'], t['ORDER']\n",
    "        cat_assigns = t['ITEMS']\n",
    "        if d== 2:\n",
    "            syst = OCS.CategorySystem(item_hash, '..\\\\..\\\\Katie2025_AlienTaxonomist\\\\static_98863bd139ec98cf6bc52549beaaf679\\\\taxonomies\\\\tree2D.json')\n",
    "        else:\n",
    "            syst = OCS.CategorySystem(item_hash, '..\\\\..\\\\Katie2025_AlienTaxonomist\\\\static_98863bd139ec98cf6bc52549beaaf679\\\\taxonomies\\\\tree3D.json')\n",
    "        orders = order_dic[f'{l}{o}']\n",
    "        marginal_like, max_like, min_like = analyze_participant(cat_assigns, orders, syst, D, lookupTree, temp)\n",
    "        log_like += marginal_like\n",
    "        best_like += max_like\n",
    "        worst_like += min_like\n",
    "        if p%50 == 0:\n",
    "            print(f'{p+1} trials processed')\n",
    "        p += 1\n",
    "    return log_like, worst_like, best_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 trials processed\n",
      "51 trials processed\n",
      "101 trials processed\n",
      "151 trials processed\n",
      "201 trials processed\n",
      "251 trials processed\n",
      "301 trials processed\n",
      "351 trials processed\n",
      "401 trials processed\n",
      "451 trials processed\n",
      "501 trials processed\n",
      "551 trials processed\n",
      "601 trials processed\n",
      "651 trials processed\n"
     ]
    }
   ],
   "source": [
    "random.seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "ordered_trials = [t for t in participant_trials if t['ORDER'] != 'a']\n",
    "log_like_ckmm, worst_like_ckmm, best_like_ckmm = estimate_model_likelihood(ordered_trials, temp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab301686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8210.012968818644 -10397.30350644622 -7711.700189885906\n"
     ]
    }
   ],
   "source": [
    "print(log_like_ckmm, worst_like_ckmm, best_like_ckmm )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe4885",
   "metadata": {},
   "source": [
    "### Random assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f1151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.281959752685427 -25.296831937719077\n",
      "-13125.876881461609\n"
     ]
    }
   ],
   "source": [
    "num_3 = len([t for t in ordered_trials if t['DEPTH'] == 3])\n",
    "num_2 = len([t for t in ordered_trials if t['DEPTH'] == 2])\n",
    "\n",
    "random_2level = np.log(1/3)*13\n",
    "random_3level = np.log(1/7)*13\n",
    "print(random_2level, random_3level)\n",
    "\n",
    "random_likelihood = (random_2level*num_2) + (random_3level*num_3)\n",
    "print(random_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proj4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
